{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sympy import Matrix, init_printing, cos, sin, rad, N\n",
    "import random\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import timeit\n",
    "import subprocess\n",
    "\n",
    "# Initialize pretty printing\n",
    "init_printing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{A} = \\begin{pmatrix} {11} & {12} & {13} \\\\ {21} & {22} & {23} \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\n",
    "a \\in \\mathbb{R}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\n",
    "\\mathbf{M} = \\begin{pmatrix} \n",
    "m_{11} & m_{12} & \\cdots & m_{1n} \\\\ \n",
    "m_{21} & m_{22} & \\cdots & m_{2n} \\\\ \n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\ \n",
    "m_{m1} & m_{m2} & \\cdots & m_{mn} \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{M}^\\top\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{M}^{-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\vec{u} \\cdot \\vec{v} = u_1v_1 + u_2v_2 + \\cdots + u_nv_n\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{T} = T_{ijk} \\quad \\text{where } i, j, k \\text{ are indices.}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1566, 0.9445, 0.8768],\n",
      "        [0.3462, 0.4169, 0.7194],\n",
      "        [0.0064, 0.4543, 0.8027],\n",
      "        [0.6691, 0.1408, 0.3926],\n",
      "        [0.4141, 0.8113, 0.1571]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{A} = \\begin{pmatrix}\n",
    "a & b \\\\\n",
    "c & d\n",
    "\\end{pmatrix}\n",
    "\\\\\n",
    "\\mathbf{A}^{-1} = \\begin{pmatrix}\n",
    "d & -b \\\\\n",
    "-c & a\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{AA}^{-1} = \\begin{pmatrix}\n",
    "ad & -bc \\\\\n",
    "-cb & ad\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}1\\\\2\\\\3\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "⎡1⎤\n",
       "⎢ ⎥\n",
       "⎢2⎥\n",
       "⎢ ⎥\n",
       "⎣3⎦"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define your vector\n",
    "vector = [1, 2, 3]\n",
    "\n",
    "# Convert the vector to a LaTeX formatted string\n",
    "Matrix(vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "len1 = 8\n",
    "deg1 = 190\n",
    "len2 = 3\n",
    "deg2 = 310\n",
    "\n",
    "# vector = [\n",
    "#     N(cos(rad(deg1))*len1 + cos(rad(deg2))*len2), \n",
    "#     N(sin(rad(deg1))*len1 + sin(rad(deg2))*len2)]\n",
    "# vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}-5.95009919503805\\\\-3.68731875069238\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "⎡-5.95009919503805⎤\n",
       "⎢                 ⎥\n",
       "⎣-3.68731875069238⎦"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vec(len, deg):\n",
    "    return len*Matrix([cos(rad(deg)), sin(rad(deg))])\n",
    "\n",
    "v = vec(8, 190)+vec(3, 310)\n",
    "N(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def det(m):\n",
    "    size = len(m)\n",
    "    det = 1\n",
    "    for row in range(size):\n",
    "        swap = row+1\n",
    "        while m[row][row] == 0:\n",
    "            if (swap == size):\n",
    "                return 0\n",
    "            m[row], m[swap] = m[swap], m[row]\n",
    "            det*=-1\n",
    "            swap+=1\n",
    "        for op in range(row+1, size):\n",
    "            for col in range(row+1, size):\n",
    "                m[op][col] = m[op][col] - m[row][col] * m[op][row] / m[row][row]\n",
    "            m[op][row] = 0\n",
    "    for i in range(size):\n",
    "        det*=m[i][i]\n",
    "    return det\n",
    "\n",
    "def mult(m1, m2):\n",
    "    dim = len(m1[0])\n",
    "    if dim != len(m2):\n",
    "        raise ValueError(\"Invalid matrix dimensions\")\n",
    "    rows = len(m1)\n",
    "    cols = len(m2[0])\n",
    "    result = [[0 for c in range(cols)] for r in range(rows)]\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            for d in range(dim):\n",
    "                result[r][c] += m1[r][d]*m2[d][c]\n",
    "    return result\n",
    "    \n",
    "def rand_matrix(size):\n",
    "    return [[torch.rand(1).item() for i in range(size)] for j in range(size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mine: 97.03636169433594\n",
      "torch: 515.4609680175781\n",
      "mine: -0.016750264986841377\n",
      "torch: -0.016750268638134003\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}0.752239644527435 & 0.364496409893036 & 0.965676724910736 & 0.62749171257019 & 0.461422443389893 & 0.691776692867279 & 0.151151895523071 & 0.440637111663818 & 0.918022036552429 & 0.11830747127533\\\\0.553320705890656 & 0.398569524288177 & 0.631999671459198 & 0.848053097724915 & 0.476605594158173 & 0.75417423248291 & 0.344964742660522 & 0.270097434520721 & 0.465959489345551 & 0.939897418022156\\\\0.829836845397949 & 0.813796997070313 & 0.234280228614807 & 0.0403961539268494 & 0.175743639469147 & 0.364281415939331 & 0.845353603363037 & 0.898287832736969 & 0.3418790102005 & 0.103809297084808\\\\0.787140071392059 & 0.690531849861145 & 0.925010681152344 & 0.619488894939423 & 0.540774703025818 & 0.73176372051239 & 0.513942837715149 & 0.923919081687927 & 0.909578621387482 & 0.383986413478851\\\\0.19734126329422 & 0.593598484992981 & 0.451926827430725 & 0.164760231971741 & 0.287022531032562 & 0.998669147491455 & 0.657650530338287 & 0.792843401432037 & 0.343869209289551 & 0.187360763549805\\\\0.332162022590637 & 0.938750505447388 & 0.767078816890717 & 0.468356072902679 & 0.480495810508728 & 0.279483139514923 & 0.517038226127625 & 0.689797639846802 & 0.150848031044006 & 0.75181770324707\\\\0.575127899646759 & 0.382499992847443 & 0.493328809738159 & 0.0350598096847534 & 0.616829037666321 & 0.310518085956573 & 0.656965792179108 & 0.183277249336243 & 0.164811432361603 & 0.448984146118164\\\\0.662189722061157 & 0.20315420627594 & 0.732528924942017 & 0.337118685245514 & 0.833122730255127 & 0.592901229858398 & 0.246380925178528 & 0.998361349105835 & 0.0556413531303406 & 0.304367363452911\\\\0.512901067733765 & 0.0725242495536804 & 0.537483811378479 & 0.0449759364128113 & 0.627033233642578 & 0.750138461589813 & 0.0970920324325562 & 0.365916907787323 & 0.571121633052826 & 0.510175228118896\\\\0.807789027690887 & 0.245030343532562 & 0.574261367321014 & 0.28870689868927 & 0.0804747939109802 & 0.825677156448364 & 0.257147789001465 & 0.857163071632385 & 0.952290177345276 & 0.43896222114563\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "⎡0.752239644527435  0.364496409893036   0.965676724910736   0.62749171257019  \n",
       "⎢                                                                             \n",
       "⎢0.553320705890656  0.398569524288177   0.631999671459198  0.848053097724915  \n",
       "⎢                                                                             \n",
       "⎢0.829836845397949  0.813796997070313   0.234280228614807  0.0403961539268494 \n",
       "⎢                                                                             \n",
       "⎢0.787140071392059  0.690531849861145   0.925010681152344  0.619488894939423  \n",
       "⎢                                                                             \n",
       "⎢0.19734126329422   0.593598484992981   0.451926827430725  0.164760231971741  \n",
       "⎢                                                                             \n",
       "⎢0.332162022590637  0.938750505447388   0.767078816890717  0.468356072902679  \n",
       "⎢                                                                             \n",
       "⎢0.575127899646759  0.382499992847443   0.493328809738159  0.0350598096847534 \n",
       "⎢                                                                             \n",
       "⎢0.662189722061157   0.20315420627594   0.732528924942017  0.337118685245514  \n",
       "⎢                                                                             \n",
       "⎢0.512901067733765  0.0725242495536804  0.537483811378479  0.0449759364128113 \n",
       "⎢                                                                             \n",
       "⎣0.807789027690887  0.245030343532562   0.574261367321014   0.28870689868927  \n",
       "\n",
       " 0.461422443389893   0.691776692867279  0.151151895523071   0.440637111663818 \n",
       "                                                                              \n",
       " 0.476605594158173   0.75417423248291   0.344964742660522   0.270097434520721 \n",
       "                                                                              \n",
       " 0.175743639469147   0.364281415939331  0.845353603363037   0.898287832736969 \n",
       "                                                                              \n",
       " 0.540774703025818   0.73176372051239   0.513942837715149   0.923919081687927 \n",
       "                                                                              \n",
       " 0.287022531032562   0.998669147491455  0.657650530338287   0.792843401432037 \n",
       "                                                                              \n",
       " 0.480495810508728   0.279483139514923  0.517038226127625   0.689797639846802 \n",
       "                                                                              \n",
       " 0.616829037666321   0.310518085956573  0.656965792179108   0.183277249336243 \n",
       "                                                                              \n",
       " 0.833122730255127   0.592901229858398  0.246380925178528   0.998361349105835 \n",
       "                                                                              \n",
       " 0.627033233642578   0.750138461589813  0.0970920324325562  0.365916907787323 \n",
       "                                                                              \n",
       " 0.0804747939109802  0.825677156448364  0.257147789001465   0.857163071632385 \n",
       "\n",
       " 0.918022036552429   0.11830747127533 ⎤\n",
       "                                      ⎥\n",
       " 0.465959489345551   0.939897418022156⎥\n",
       "                                      ⎥\n",
       "  0.3418790102005    0.103809297084808⎥\n",
       "                                      ⎥\n",
       " 0.909578621387482   0.383986413478851⎥\n",
       "                                      ⎥\n",
       " 0.343869209289551   0.187360763549805⎥\n",
       "                                      ⎥\n",
       " 0.150848031044006   0.75181770324707 ⎥\n",
       "                                      ⎥\n",
       " 0.164811432361603   0.448984146118164⎥\n",
       "                                      ⎥\n",
       " 0.0556413531303406  0.304367363452911⎥\n",
       "                                      ⎥\n",
       " 0.571121633052826   0.510175228118896⎥\n",
       "                                      ⎥\n",
       " 0.952290177345276   0.43896222114563 ⎦"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = rand_matrix(10)\n",
    "ten = torch.tensor(vec).float()\n",
    "m = Matrix(vec)\n",
    "\n",
    "cycles = 1000\n",
    "\n",
    "start = time.time()\n",
    "a = det(vec)\n",
    "end = time.time()\n",
    "print(\"mine: \" + str((end-start)*1000000))\n",
    "\n",
    "start = time.time()\n",
    "b = torch.det(ten)\n",
    "end = time.time()\n",
    "print(\"torch: \" + str((end-start)*1000000))\n",
    "\n",
    "\n",
    "print(\"mine: \" + str(a))\n",
    "print(\"torch: \" + str(b.item()))\n",
    "N(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# ts1 = []\n",
    "# for i in range(cycles):\n",
    "#     ts1.append(torch.tensor(rand_matrix(9)).float())\n",
    "\n",
    "# ts2 = []\n",
    "# for i in range(cycles):\n",
    "#     ts2.append(torch.tensor(rand_matrix(9)).float())\n",
    "\n",
    "# start = time.time()\n",
    "# for i in range(1):\n",
    "#     m1 = mult(v1, v2)\n",
    "# end = time.time()\n",
    "# print(\"mine: \" + str((end-start)*1000000))\n",
    "\n",
    "# start = time.time()\n",
    "# for i in range(cycles):\n",
    "#     m2 = ts1[i] @ ts2[i]\n",
    "# end = time.time()\n",
    "# print(\"torch: \" + str((end-start)*1000000))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to cuda: 55533.88595581055\n",
      "gpu: 289.67857360839844\n",
      "transfer: 6518.125534057617\n"
     ]
    }
   ],
   "source": [
    "size = 2048\n",
    "\n",
    "v1 = rand_matrix(size)\n",
    "c1 = torch.tensor(v1).float()\n",
    "\n",
    "\n",
    "\n",
    "# g1 = torch.tensor(v1).float().to(\"cuda\")\n",
    "\n",
    "v2 = rand_matrix(size)\n",
    "c2 = torch.tensor(v2).float()\n",
    "# g2 = torch.tensor(v2).float().to(\"cuda\")\n",
    "\n",
    "start = time.time()\n",
    "g1 = c1.to(\"cuda\")\n",
    "g2 = c2.to(\"cuda\")\n",
    "end = time.time()\n",
    "print(\"gpu: \" + str((end-start)*1000000))\n",
    "\n",
    "# %timeit t1 @ t2\n",
    "# %timeit mult(v1, v2)\n",
    "\n",
    "# Warm-up\n",
    "# for _ in range(100):\n",
    "#     torch.matmul(torch.rand(500,500).to(\"mps\"), torch.rand(500,500).to(\"mps\"))\n",
    "\n",
    "# start = time.time()\n",
    "# r1 = c1 @ c2\n",
    "# end = time.time()\n",
    "# print(\"cpu: \" + str((end-start)*1000000))\n",
    "\n",
    "start = time.time()\n",
    "r2 = g1 @ g2\n",
    "end = time.time()\n",
    "print(\"gpu: \" + str((end-start)*1000000))\n",
    "\n",
    "start = time.time()\n",
    "r_cpu = r2.cpu()\n",
    "end = time.time()\n",
    "print(\"transfer: \" + str((end-start)*1000000))\n",
    "\n",
    "# start = time.time()\n",
    "# Matrix(mult(v1, v2))\n",
    "# end = time.time()\n",
    "# print(\"mine: \" + str((end-start)*1000000))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 1141057.9681396484\n"
     ]
    }
   ],
   "source": [
    "# Assuming your compiled C program is named 'matmul' and is in the current directory\n",
    "start = time.time()\n",
    "result = subprocess.run(['../c/matmul'])\n",
    "end = time.time()\n",
    "print(\"c: \" + str((end-start)*1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to cuda: 55465.2214050293\n",
      "mult: 56.98204040527344\n",
      "to cpu: 1293.6592102050781\n",
      "to cuda: 1890.1824951171875\n",
      "mult: 56.98204040527344\n",
      "to cpu: 1243.3528900146484\n",
      "to cuda: 1909.9712371826172\n",
      "mult: 67.23403930664062\n",
      "to cpu: 4726.886749267578\n",
      "to cuda: 1959.5623016357422\n",
      "mult: 66.04194641113281\n",
      "to cpu: 1249.7901916503906\n",
      "to cuda: 1991.9872283935547\n",
      "mult: 128.26919555664062\n",
      "to cpu: 4884.7198486328125\n",
      "to cuda: 1883.0299377441406\n",
      "mult: 66.99562072753906\n",
      "to cpu: 4705.4290771484375\n",
      "to cuda: 1861.0954284667969\n",
      "mult: 68.90296936035156\n",
      "to cpu: 4748.58283996582\n",
      "to cuda: 1864.1948699951172\n",
      "mult: 69.14138793945312\n",
      "to cpu: 1268.148422241211\n",
      "to cuda: 1924.0379333496094\n",
      "mult: 68.90296936035156\n",
      "to cpu: 1243.59130859375\n",
      "to cuda: 1883.2683563232422\n",
      "mult: 68.66455078125\n",
      "to cpu: 1222.6104736328125\n"
     ]
    }
   ],
   "source": [
    "size = 2048\n",
    "\n",
    "for i in range(0, 10):\n",
    "    v1 = rand_matrix(size)\n",
    "    c1 = torch.tensor(v1).float()\n",
    "    v2 = rand_matrix(size)\n",
    "    c2 = torch.tensor(v2).float()\n",
    "\n",
    "    start = time.time()\n",
    "    g1 = c1.to(\"cuda\")\n",
    "    g2 = c2.to(\"cuda\")\n",
    "    end = time.time()\n",
    "    print(\"to cuda: \" + str((end-start)*1000000))\n",
    "\n",
    "    start = time.time()\n",
    "    r2 = g1 @ g2\n",
    "    end = time.time()\n",
    "    print(\"mult: \" + str((end-start)*1000000))\n",
    "\n",
    "    start = time.time()\n",
    "    r_cpu = r2.cpu()\n",
    "    end = time.time()\n",
    "    print(\"to cpu: \" + str((end-start)*1000000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
